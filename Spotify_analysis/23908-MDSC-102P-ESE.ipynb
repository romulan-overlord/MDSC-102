{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: All outputs have been cleared to reduce the size of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./archive/spotify_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1159764 entries, 0 to 1159763\n",
      "Data columns (total 20 columns):\n",
      " #   Column            Non-Null Count    Dtype  \n",
      "---  ------            --------------    -----  \n",
      " 0   Unnamed: 0        1159764 non-null  int64  \n",
      " 1   artist_name       1159749 non-null  object \n",
      " 2   track_name        1159763 non-null  object \n",
      " 3   track_id          1159764 non-null  object \n",
      " 4   popularity        1159764 non-null  int64  \n",
      " 5   year              1159764 non-null  int64  \n",
      " 6   genre             1159764 non-null  object \n",
      " 7   danceability      1159764 non-null  float64\n",
      " 8   energy            1159764 non-null  float64\n",
      " 9   key               1159764 non-null  int64  \n",
      " 10  loudness          1159764 non-null  float64\n",
      " 11  mode              1159764 non-null  int64  \n",
      " 12  speechiness       1159764 non-null  float64\n",
      " 13  acousticness      1159764 non-null  float64\n",
      " 14  instrumentalness  1159764 non-null  float64\n",
      " 15  liveness          1159764 non-null  float64\n",
      " 16  valence           1159764 non-null  float64\n",
      " 17  tempo             1159764 non-null  float64\n",
      " 18  duration_ms       1159764 non-null  int64  \n",
      " 19  time_signature    1159764 non-null  int64  \n",
      "dtypes: float64(9), int64(7), object(4)\n",
      "memory usage: 177.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_df = df.drop(['Unnamed: 0', 'artist_name', 'track_name', 'track_id', 'key', 'genre', 'mode', 'valence', 'time_signature'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(distribution_df, x='danceability', color='year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.probplot(distribution_df.danceability, plot = plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skew for Danceability = -0.30015795151454894\n"
     ]
    }
   ],
   "source": [
    "print(f'Skew for Danceability = {distribution_df.danceability.skew()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop records that have 0 as danceability\n",
    "live_df = distribution_df[distribution_df.danceability > 0]\n",
    "normal_liveness = stats.boxcox(live_df.danceability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "live_df.loc[:, 'danceability'] = normal_liveness[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(live_df, x='danceability', color='year', nbins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.probplot(live_df.danceability, plot = plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skew for Danceability = -0.13764762979815398\n"
     ]
    }
   ],
   "source": [
    "print(f'Skew for Danceability = {live_df.danceability.skew()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But the original data has a low enough skewness, so let us proceed with the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us assume the following hypothesis for the Danceability distribution:\n",
    "$$\n",
    "H_0 : \\mu = 0.52\n",
    "\\\\\n",
    "vs\n",
    "\\\\\n",
    "H_1 : \\mu \\neq 0.52\n",
    "$$\n",
    "\n",
    "Here, Variance is unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population Mean = 0.5374382319161484\n",
      "Sample Mean = 0.5373319999999999\n",
      "Population variance = 0.034032145985789214\n",
      "Sample variance = 0.03946170522828283\n"
     ]
    }
   ],
   "source": [
    "population_mean = distribution_df.danceability.mean()\n",
    "population_variance = distribution_df.danceability.var()\n",
    "sample_size = 100\n",
    "alpha = 0.05\n",
    "mu = 0.52\n",
    "\n",
    "sample_df = distribution_df.sample(n=sample_size, random_state=26)\n",
    "sample_mean = sample_df.danceability.mean()\n",
    "\n",
    "# We estimate variance\n",
    "var_ = 0\n",
    "n = sample_df.shape[0]\n",
    "for x in sample_df.danceability:\n",
    "    var_ += (x-sample_mean)**2\n",
    "var_ = var_ / (n - 1)\n",
    "print(f'Population Mean = {population_mean}\\nSample Mean = {sample_mean}')\n",
    "print(f'Population variance = {population_variance}\\nSample variance = {var_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P Value = 0.3829407944295715\n",
      "Level of Significance = 0.05\n",
      "Reject H_0: False\n"
     ]
    }
   ],
   "source": [
    "Z_cal = (sample_mean - 0.52)/np.sqrt(var_/n)\n",
    "p_value = 2 * (1 - (stats.norm.cdf(np.abs(Z_cal))))\n",
    "\n",
    "print(f'P Value = {p_value}\\nLevel of Significance = {alpha}\\nReject H_0: {p_value < alpha}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the variance:\n",
    "$$\n",
    "H_0 : \\sigma^2 = 0.03\n",
    "\\\\\n",
    "vs\n",
    "\\\\\n",
    "H_1 : \\sigma^2 \\neq 0.03\n",
    "\\\\\n",
    "\\text{Given:}\n",
    "\\\\\n",
    "\\mu = 0.5374\n",
    "$$\n",
    "\n",
    "Here, mean is known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  var_ stores the sample variance\n",
    "# Calculating thetest statistic for Variance:\n",
    "\n",
    "sigma = 0.03\n",
    "\n",
    "chi2_cal = ((sample_size - 1) * var_)/sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Now, we calculate the p-value as:}\\\\\n",
    "\\text{p-value} = 2 * P(\\chi^2 > \\chi^2_{cal})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P Value = 0.04556913649575001\n",
      "Level of Significance = 0.05\n",
      "Reject H_0: True\n"
     ]
    }
   ],
   "source": [
    "p_value = 2 * (1 - stats.chi2.cdf(chi2_cal, sample_size))\n",
    "print(f'P Value = {p_value}\\nLevel of Significance = {alpha}\\nReject H_0: {p_value < alpha}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, let us look at the Liveness feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(distribution_df, x='liveness', color='year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skew for Liveness = 1.9556522316451774\n"
     ]
    }
   ],
   "source": [
    "print(f'Skew for Liveness = {distribution_df.liveness.skew()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.probplot(distribution_df.liveness, plot = plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data is not normal. Let us make it normal using the boxcox method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop records that have 0 as liveness\n",
    "live_df = distribution_df[distribution_df.liveness > 0]\n",
    "normal_liveness = stats.boxcox(live_df.liveness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "live_df.loc[:, 'liveness'] = normal_liveness[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(live_df, x='liveness', color='year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skew for Liveness = 0.024711234325236153\n"
     ]
    }
   ],
   "source": [
    "print(f'Skew for Liveness = {live_df.liveness.skew()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.probplot(live_df.liveness, plot = plt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skew for Liveness = 0.024711234325236153\n"
     ]
    }
   ],
   "source": [
    "print(f'Skew for Liveness = {live_df.liveness.skew()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data is now somewhat normal. Let us test the following hypotheses:\n",
    "\n",
    "$$\n",
    "H_0 : \\mu = -2.5\n",
    "\\\\\n",
    "vs\n",
    "\\\\\n",
    "H_1 : \\mu > -2.5\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population Mean = -2.4602723791406285\n",
      "Sample Mean = -2.7187678821554817\n",
      "Population variance = 1.4274470291243428\n",
      "Sample variance = 1.1531259644239455\n"
     ]
    }
   ],
   "source": [
    "population_mean = live_df.liveness.mean()\n",
    "population_variance = live_df.liveness.var()\n",
    "sample_size = 100\n",
    "alpha = 0.05\n",
    "mu = -2.5\n",
    "\n",
    "sample_df = live_df.sample(n=sample_size, random_state=99)\n",
    "sample_mean = sample_df.liveness.mean()\n",
    "\n",
    "# We estimate variance\n",
    "var_ = 0\n",
    "n = sample_df.shape[0]\n",
    "for x in sample_df.liveness:\n",
    "    var_ += (x-sample_mean)**2\n",
    "var_ = var_ / (n - 1)\n",
    "print(f'Population Mean = {population_mean}\\nSample Mean = {sample_mean}')\n",
    "print(f'Population variance = {population_variance}\\nSample variance = {var_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P Value = 0.020812295647389595\n",
      "Level of Significance = 0.05\n",
      "Reject H_0: True\n"
     ]
    }
   ],
   "source": [
    "Z_cal = (sample_mean - mu)/np.sqrt(var_/n)\n",
    "p_value = stats.norm.cdf(Z_cal)\n",
    "\n",
    "print(f'P Value = {p_value}\\nLevel of Significance = {alpha}\\nReject H_0: {p_value < alpha}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the variance:\n",
    "$$\n",
    "H_0 : \\sigma^2 = 1.4\n",
    "\\\\\n",
    "vs\n",
    "\\\\\n",
    "H_1 : \\sigma^2 < 1.4\n",
    "\\\\\n",
    "\\text{Given:}\n",
    "\\\\\n",
    "\\mu = -2.7188\n",
    "$$\n",
    "\n",
    "Here, mean is known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.54247891283616\n"
     ]
    }
   ],
   "source": [
    "#  var_ stores the sample variance\n",
    "# Calculating thetest statistic for Variance:\n",
    "\n",
    "sigma = 1.4\n",
    "\n",
    "chi2_cal = ((sample_size - 1) * var_)/sigma\n",
    "\n",
    "print(chi2_cal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Now, we calculate the p-value as:}\\\\\n",
    "\\text{p-value} = P(\\chi^2 < \\chi^2_{cal})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P Value = 0.08891779786169042\n",
      "Level of Significance = 0.05\n",
      "Reject H_0: False\n"
     ]
    }
   ],
   "source": [
    "p_value = (stats.chi2.cdf(chi2_cal, sample_size))\n",
    "print(f'P Value = {p_value}\\nLevel of Significance = {alpha}\\nReject H_0: {p_value < alpha}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del live_df\n",
    "del normal_liveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(distribution_df.drop('year', axis=1).corr().round(2), text_auto=True, aspect='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We see that features such as Energy and Loudness are very positively corelated, while features like energy and acousticness or loudness and acousticness are negatively correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(distribution_df.sample(1000), x='energy', y='loudness', trendline='ols')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(distribution_df.sample(1000), x='energy', y='acousticness', trendline='ols')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(distribution_df.sample(1000), x='loudness', y='acousticness', trendline='ols')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us Study the genres now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = df.year.value_counts()\n",
    "years = list(years.sort_index().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_top100 = {}\n",
    "for year in years:\n",
    "    yearly_top100[year] = df[df['year'] == year].sort_values(by='popularity', axis=0, ascending=False).head(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are constructing a dataframe that stores the frequency of genres in the top 5000 songs over the years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_dict = {}\n",
    "for year in years:\n",
    "    genres = yearly_top100[year].genre.value_counts()\n",
    "    for genre, count in genres.items():\n",
    "        if genre_dict.get(genre):\n",
    "            genre_dict[genre].append((year, count))\n",
    "        else:\n",
    "            genre_dict[genre] = [(year, count),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_counts = pd.DataFrame(index=years)\n",
    "for key in genre_dict.keys():\n",
    "    temp = pd.Series(index=years)\n",
    "    for gen in genre_dict[key]:\n",
    "        temp[gen[0]] = gen[1]\n",
    "    if gen[0] > 2018 and temp.sum() > 2500:\n",
    "        genre_counts[key] = temp\n",
    "        genre_counts[key].fillna(temp.min(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(genre_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=7, cols=2, subplot_titles=tuple(genre_counts.columns))\n",
    "index = 0\n",
    "for row in range(1,8):\n",
    "    for col in range(1,3):\n",
    "        fig.add_trace(go.Scatter(x = years, y = genre_counts.iloc[:,index], mode='lines'), row=row, col=col)\n",
    "        index += 1\n",
    "\n",
    "# Update subplot layout\n",
    "fig.update_layout(title=\"Genre Trends\", showlegend=False, height=1200)\n",
    "\n",
    "# Show the subplot figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferences\n",
    "\n",
    "* Alt-rock has gradually declined in popularity.\n",
    "* Dance and Pop have remained fairly stable in popularity.\n",
    "    * Interestingly, in the year 2015, Dance plummeted in popularity, while Pop spiked.\n",
    "    * Electro music also had a spike in popularity during 2015. That was the year edm and dubstep became mainstream.\n",
    "* Hip Hop, K-pop, French music and Indie-pop have also been growing in popularity. Hip Hop is currently the most popular Genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(genre_counts.corr().round(2), text_auto=True, aspect='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* On further analysing the decline of alt-rock, it is strongly negatively correlated to the following genres: \n",
    "    * Indie-Pop\n",
    "    * K-pop\n",
    "    * French\n",
    "    * Country\n",
    "    * Hip-Hop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = ('indie-pop', 'k-pop', 'french', 'country', 'hip-hop')\n",
    "fig = make_subplots(rows=5, cols=1, subplot_titles= genres)\n",
    "index=0\n",
    "for row in range(1,6):\n",
    "    fig.add_trace(go.Scatter(x = years, y = genre_counts.loc[:,genres[index]], text=[genres[index] for year in years], hoverinfo='x+y+text', name=genres[index]), row=row, col=1)\n",
    "    fig.add_trace(go.Scatter(x = years, y = genre_counts.loc[:,'alt-rock'], text=['alt_rock' for year in years], hoverinfo='x+y+text', name='alt-rock', line=dict(color='purple', width=2)), row=row, col=1)\n",
    "    index += 1\n",
    "\n",
    "# Update subplot layout\n",
    "fig.update_layout(title=\"Genre Trends\", showlegend=True, height=1200)\n",
    "\n",
    "# Show the subplot figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us try and study the reasons why pop and dance genres have dominated the marcket so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_df = pd.concat([yearly_top100[year] for year in years])\n",
    "top_df = pd.concat([top_df[top_df['genre'] == 'pop'], top_df[top_df['genre'] == 'dance']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = ['danceability',\n",
    " 'energy',\n",
    " 'key',\n",
    " 'loudness',\n",
    " 'mode',\n",
    " 'speechiness',\n",
    " 'acousticness',\n",
    " 'liveness',\n",
    " 'valence',\n",
    " 'tempo',]\n",
    "\n",
    "fig, ax = plt.subplots(5,2,figsize=(10,30))\n",
    "\n",
    "index=0\n",
    "for row in range(5):\n",
    "    for col in range(2):\n",
    "        print(f'Plotting: {feature_list[index]}')\n",
    "        sns.histplot(top_df, x=feature_list[index], hue='genre', ax=ax[row,col])\n",
    "        ax[row,col].grid()\n",
    "        index += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_df = pd.concat([yearly_top100[year] for year in years])\n",
    "top_df = pd.concat([top_df[top_df['genre'] == 'hip-hop'], top_df[top_df['genre'] == 'dance']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = ['danceability',\n",
    " 'energy',\n",
    " 'key',\n",
    " 'loudness',\n",
    " 'mode',\n",
    " 'speechiness',\n",
    " 'acousticness',\n",
    " 'liveness',\n",
    " 'valence',\n",
    " 'tempo',]\n",
    "\n",
    "fig, ax = plt.subplots(5,2,figsize=(15,25))\n",
    "# fig.suptitle('Variation of features between hip-hop and dance')\n",
    "index=0\n",
    "for row in range(5):\n",
    "    for col in range(2):\n",
    "        print(f'Plotting: {feature_list[index]}')\n",
    "        sns.histplot(top_df, x=feature_list[index], hue='genre', ax=ax[row,col])\n",
    "        ax[row,col].grid()\n",
    "        index += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean danceability for Dance = 0.6607343693530899\n",
      "Mean danceability for Hip-Hop = 0.7135509607721597\n",
      "Mean energy for Dance = 0.7299632092518974\n",
      "Mean energy for Hip-Hop = 0.6698568974586027\n"
     ]
    }
   ],
   "source": [
    "dance_danceability_mean = top_df[top_df.genre == 'dance'].danceability.mean()\n",
    "hiphop_danceability_mean = top_df[top_df.genre == 'hip-hop'].danceability.mean()\n",
    "\n",
    "dance_energy_mean = top_df[top_df.genre == 'dance'].energy.mean()\n",
    "hiphop_energy_mean = top_df[top_df.genre == 'hip-hop'].energy.mean()\n",
    "\n",
    "print(f'Mean danceability for Dance = {dance_danceability_mean}')\n",
    "print(f'Mean danceability for Hip-Hop = {hiphop_danceability_mean}')\n",
    "\n",
    "print(f'Mean energy for Dance = {dance_energy_mean}')\n",
    "print(f'Mean energy for Hip-Hop = {hiphop_energy_mean}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Let X represent the population of dance genre, and Y represent the hip-hop genre, and the energy feature both follow a normal distribution.}\n",
    "\\\\\n",
    "X \\sim N(\\mu_1, \\sigma_1^2)\n",
    "\\\\\n",
    "Y \\sim N(\\mu_2, \\sigma_2^2)\n",
    "\\\\\n",
    "H_0 : \\mu_1 = \\mu_2\n",
    "\\\\\n",
    "\\text{vs}\n",
    "\\\\\n",
    "H_1: \\mu_1 \\neq \\mu_2\n",
    "$$\n",
    "#### Or equivalently,<br>\n",
    "$$\n",
    "H_0 : \\mu_1 - \\mu_2 \\lt \\delta\n",
    "\\\\\n",
    "\\text{vs}\n",
    "\\\\\n",
    "H_1: \\mu_1 - \\mu_2 \\gt \\delta\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hip-Hop Energy:\n",
      "Mean Energy = 0.6649299999999999\n",
      "Energy Variance = 0.02594675262626262\n",
      "\n",
      "Dance Energy:\n",
      "Mean Energy = 0.7317100000000001\n",
      "Energy Variance = 0.02458228878787879\n"
     ]
    }
   ],
   "source": [
    "sample_size = 100\n",
    "random_state = 55\n",
    "hiphop = top_df[top_df.genre == 'hip-hop'].sample(sample_size, random_state = random_state)\n",
    "dance = top_df[top_df.genre == 'dance'].sample(sample_size, random_state = random_state)\n",
    "\n",
    "print('Hip-Hop Energy:')\n",
    "print(f'Mean Energy = {hiphop.energy.mean()}\\nEnergy Variance = {hiphop.energy.var()}')\n",
    "print('\\nDance Energy:')\n",
    "print(f'Mean Energy = {dance.energy.mean()}\\nEnergy Variance = {dance.energy.var()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level of Significance = 0.05\n",
      "Z calculated = 2.5259506332776325\n",
      "p-value = 0.011538569395171283\n",
      "Reject H_0: True\n"
     ]
    }
   ],
   "source": [
    "delta = 0.01\n",
    "alpha = 0.05\n",
    "hiphop_mean = hiphop.energy.mean()\n",
    "hiphop_var = hiphop.energy.var()\n",
    "\n",
    "dance_mean = dance.energy.mean()\n",
    "dance_var = dance.energy.var()\n",
    "\n",
    "Z_cal = np.abs((dance_mean - hiphop_mean) - delta) / np.sqrt((hiphop_var + dance_var) / sample_size)\n",
    "\n",
    "p_value = 2 * (1 - stats.norm.cdf(Z_cal))\n",
    "\n",
    "print(f'Level of Significance = {alpha}')\n",
    "print(f'Z calculated = {Z_cal}')\n",
    "print(f'p-value = {p_value}')\n",
    "print(f'Reject H_0: {p_value < alpha}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
